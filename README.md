# Gradient Boosting Machines and XGBoost
![GitHub Logo](https://s3.ap-south-1.amazonaws.com/greyatom-social/GreyAtom-logo.png)

You will learn more about Gradient Boosting and apply them on your datset

## At a glance
* In Class Instruction: 4 Hours
* In Class code along Dataset: Lending Club

* Skills Rehearsed
  * Apply Hyperparameter Tuning techniques in Python using sklearn

## In-Class Activities
* Recap of previous session
* Instructor Concept building
* Periodic Recap - Closer to the end of session
* In Class Assignments - Motivation

## Pre Reads
1. [XGBoost Documentation](http://xgboost.readthedocs.io/en/latest/python/python_intro.html)
2. [Complete Guide to Parameter Tuning in XGBoost](https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/)

## Learning Objective

After this session , you'll be able to
1. Learn what Boosting is and how use it in ML
2. Learn what Gradient Boosting Machines are and how to use them to build ML models
3. Learn to configure GBM using early-stopping and hyperparameter tuning to achieve superior performance
4. Learn how to interpret XGBoost models


## Slides
Check the Jupyter Notebook in the top right of the screen


## Post Reads
1. [XGBoost: A Scalable Tree Boosting System](http://www.kdd.org/kdd2016/papers/files/rfp0697-chenAemb.pdf)
2. [Gradient Boosting](https://en.wikipedia.org/wiki/Gradient_boosting)


## Project 
 Check out project readme!
